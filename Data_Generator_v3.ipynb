{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf = pd.read_csv('../data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19570\n",
      "4867136\n"
     ]
    }
   ],
   "source": [
    "unique_sources = trainingdf['Source'].unique()\n",
    "print(len(unique_sources))\n",
    "unique_sinks = trainingdf['Sink'].unique()\n",
    "print(len(unique_sinks))\n",
    "edgeStringSet = set(trainingdf['string'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Edges - Mapping 1 Source -> 10 Sinks, ensuring edge generated dont exist in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeData = []\n",
    "for source_node in unique_sources:\n",
    "    counter = 0\n",
    "    while counter < 10:\n",
    "        sink = unique_sinks[np.random.randint(len(unique_sinks))]\n",
    "        compareEdge = str(source_node) + ',' + str(sink)\n",
    "        if compareEdge not in edgeStringSet:\n",
    "            fakeData.append((source_node,sink,0))\n",
    "            counter += 1\n",
    "fakeDataDF = pd.DataFrame.from_records(fakeData, columns=['Source','Sink','Value'])\n",
    "fakeDataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='the_destination'></a>True Edges - Random sampling from Training Dataset of 24m edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = True\n",
    "while check:\n",
    "    trueDataDF = trainingdf.sample(195705, replace=False, random_state=470350637)\n",
    "    if trueDataDF['string'].nunique() >= 195700:\n",
    "        trueDataDF = trueDataDF.drop_duplicates(subset=['string'])\n",
    "        check = False\n",
    "trueDataDF.drop(columns=['string'], axis=1, inplace=True)\n",
    "trueDataDF['Value'] = 1\n",
    "trueDataDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both to get random generated data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedDataDF = pd.concat([trueDataDF,fakeDataDF])\n",
    "generatedDataDF.to_csv('../data/400k_NewDataset' + str(time.strftime(\"%c\")) + '.cav', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to list for processing against NetworkX models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedDataDFtemp = generatedDataDF.drop(columns=['Value'], axis=1)\n",
    "generatedDataList = generatedDataDFtemp.to_records(index=False)\n",
    "generatedDataList = generatedDataList.tolist()\n",
    "len(generatedDataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24004361"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_child_counts = {}\n",
    "node_child_sets = {}\n",
    "items = []\n",
    "with open('../data/train.txt', 'rt') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        numbers = line.split('\\t')\n",
    "        source = int(numbers[0])\n",
    "        node_child_counts[source] = len(numbers)-1\n",
    "        node_child_sets[source] = set(numbers[1:])\n",
    "        for sink in numbers[1:]:\n",
    "            items.append((source, int(sink),1)) # Tweak to build graph with edge weight of 1\n",
    "        line = f.readline()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DirectedGraph and converting it to an Undirected one for applying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()\n",
    "DG.add_weighted_edges_from(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = DG.to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Clearing memory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del DG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adamic Adar Coeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AApreds = nx.adamic_adar_index(G, generatedDataList)\n",
    "AAlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=391400) as pbar:\n",
    "    for source, sink, prediction in AApreds:\n",
    "        AAlist.append((source, sink, prediction))\n",
    "        counter -= 1\n",
    "        pbar.update(1)\n",
    "AAdf = pd.DataFrame.from_records(AAlist,columns=['Source','Sink','AAprediction'])\n",
    "AAdf.to_csv('../data/400k_NewDataset_AA' + str(time.strftime(\"%c\")) + '.csv', index = False)\n",
    "AAdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAdf = pd.read_csv('../data/400k_NewDataset_AA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_neighbor_list = []\n",
    "cncount = len(generatedDataList)\n",
    "with tqdm(total=cncount) as pbar:\n",
    "    for source, sink in generatedDataList:\n",
    "        common_neighbor_list.append((source, sink, len(list(nx.common_neighbors(G,source,sink)))))\n",
    "        cncount = cncount - 1\n",
    "        pbar.update(1)\n",
    "common_neighbor_df = pd.DataFrame.from_records(common_neighbor_list,columns=['Source','Sink','common_neighbors'])\n",
    "common_neighbor_df.to_csv('../data/400k_NewDataset_CN' + str(time.strftime(\"%c\")) + '.csv', index = False)\n",
    "common_neighbor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_neighbor_df = pd.read_csv('../data/400k_NewDataset_CN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducingDF = pd.merge(common_neighbor_df, AAdf, left_on=['Source','Sink'], right_on=['Source','Sink'], how='outer', left_index=False, right_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDF(a, b):\n",
    "    new = str(a) + ',' + str(b)\n",
    "    if new in edgeStringSet:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducingDF['exist_in_training_dataset'] = reducingDF[['Source','Sink']].apply(lambda x: validateDF(x[0],x[1]), axis=1)\n",
    "reducingDF.to_csv('../data/400k_NewDataset_Final' + str(time.strftime(\"%c\")) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sink</th>\n",
       "      <th>AAprediction</th>\n",
       "      <th>JA</th>\n",
       "      <th>PA</th>\n",
       "      <th>Id</th>\n",
       "      <th>common_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2184483</td>\n",
       "      <td>1300190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3151356</td>\n",
       "      <td>1452193</td>\n",
       "      <td>0.407705</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>102306</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579396</td>\n",
       "      <td>193159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>418</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1406432</td>\n",
       "      <td>2481036</td>\n",
       "      <td>1.238898</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>2838</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2389638</td>\n",
       "      <td>593017</td>\n",
       "      <td>0.802812</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>62196</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source     Sink  AAprediction        JA      PA  Id  common_neighbors\n",
       "0  2184483  1300190      0.000000  0.000000     435   1                 0\n",
       "1  3151356  1452193      0.407705  0.006260  102306   2                 4\n",
       "2  1579396   193159      0.000000  0.000000     418   3                 0\n",
       "3  1406432  2481036      1.238898  0.062500    2838   4                 7\n",
       "4  2389638   593017      0.802812  0.012072   62196   5                 6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF = pd.read_csv('../data/testData_NetworkX_analysis_01Sep18.csv')\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
